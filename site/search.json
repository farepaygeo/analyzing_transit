[
  {
    "objectID": "cleaning a gtfs.html",
    "href": "cleaning a gtfs.html",
    "title": "Cleaning a GTFS using gtfstools",
    "section": "",
    "text": "On this page, use some functions from gtfstools as well as the tidyverse to clean a GTFS. We will explore some of the structure of the GTFS and prepare it for calculations we will perform on subsequent pages.\n\nlibrary(gtfstools)\nlibrary(dplyr)\n\nread_gtfs reads a GTFS, holding it in your environment as a special datatable: a dt_gtfs.\n\ngtfs <- read_gtfs(\"./data/gtfs 11_2018.zip\")\nclass(gtfs)\n\n[1] \"dt_gtfs\" \"gtfs\"    \"list\"   \n\nsummary(gtfs)\n\nA gtfs object with the following tables and respective numbers of entries in each:\n        agency       calendar calendar_dates         routes         shapes \n             1              4              6            107         280190 \n    stop_times          stops      transfers          trips \n        745329           4726           1266          15484 \n\n\nFor this exercise, we are using a GTFS published by the Maryland Transit Administration (MTA), containing information about service from September 2018 into February 2019. That information is contained, appropriately, in the “calendar” table of the dt_gtfs.\n\ngtfs$calendar$start_date\n\n[1] \"2018-09-02\" \"2018-09-02\" \"2018-09-02\" \"2018-09-02\"\n\ngtfs$calendar$end_date\n\n[1] \"2019-02-02\" \"2019-02-02\" \"2019-02-02\" \"2019-02-02\"\n\n\nThere are a bunch of other tables here, containing rows upon rows of information about transit service circa Fall and Winter, 2018-19. One of the tables is “routes” which contains information about route names and types.\n\nunique(gtfs$routes$route_type)\n\n[1] 3 1 0 2\n\n\nIn the GTFS Reference, light rail is assigned type “0”, subway is assigned type “1”, intercity rail is assigned type “2”, and bus is assigned type “3”. Knowing this, we can use the filter_by_route_type function in gtfstools to filter the entire dt_gtfs to just the information about bus service.\n\n##filter down gtfs to just bus routes\ngtfs <- filter_by_route_type(gtfs, route_type = 3)\n##from 4 types to 1\nunique(gtfs$routes$route_type) \n\n[1] 3\n\n\nAgencies assign their own route_ids and these change with each new GTFS published. However, route_id corresponds to route_short_name, which does not change unless a route is eliminated or renamed.\n\nlength(unique(gtfs$routes$route_id))\n\n[1] 102\n\nlength(unique(gtfs$routes$route_short_name))\n\n[1] 102\n\n#it's 1:1\n\nIn the MTA bus system, routes 95 and greater are commuter and supplementary services. A number of these commuter routes serve Washington D.C. For this analysis, we are only interested in regular services in Baltimore City and that extend into surrounding Baltimore and Anne Arundel Counties.\nIn the next chunk, we will pass a range of numbers representing the extraneous bus routes to a character vector. Then, we will subset rows that have a route_short_name match in the character vector. We can pass the values from the resulting route_id column to a new character vector, which we can subsequently use with gtfstools filter_by_route_id function.\n\n##create vector of route short names\ncomm_names <- as.character(95:850)\n##subset route ids that have a match in the comm_names vector\nroute_ids <- gtfs$routes[which(gtfs$routes$route_short_name %in% comm_names), \"route_id\"]\n##pass the route ids to a new vector\ncomm_ids <- c(route_ids$route_id)\n##filter by route id\ngtfs_fil <- filter_by_route_id(gtfs, comm_ids, keep = FALSE) ##seeya\n\nlength(unique(gtfs_fil$routes$route_id))\n\n[1] 55\n\n\nGTFS stores arrival and departure times as a character in HH:MM:SS format.\n\nhead(gtfs_fil$stop_times$arrival_time)\n\n[1] \"20:43:00\" \"20:43:57\" \"20:44:53\" \"20:45:33\" \"20:46:15\" \"20:47:21\"\n\n\nThe convert_time_to_seconds function allows us to convert all arrival and departure times from HH:MM:SS format to seconds after midnight. This is going to make later calculations much easier. It also helps iron out some quirks that come with transit scheduling, since a single day of service can often extend beyond 24 hours.\n\ngtfs_fil <- convert_time_to_seconds(gtfs_fil)\nhead(gtfs_fil$stop_times$arrival_time_secs)\n\n[1] 74580 74637 74693 74733 74775 74841\n\n\nFinally, I’m going to break the GTFS down into weekday (Monday to Friday) and weekend (Saturday and Sunday) service. Service is often pared back on the weekends and it may be useful to exclude those trips from our subsequent calculations.\nAgencies assign service IDs to differentiate days of the week. There might be additional service IDs that pertain to special holiday or event services.\n\ngtfs_fil$calendar\n\n   service_id monday tuesday wednesday thursday friday saturday sunday\n1:          1      1       1         1        1      1        0      0\n2:          2      0       0         0        0      0        1      0\n3:          3      0       0         0        0      0        0      1\n   start_date   end_date\n1: 2018-09-02 2019-02-02\n2: 2018-09-02 2019-02-02\n3: 2018-09-02 2019-02-02\n\n\ngtfstools handles this type of filtering, once again, with a function. We’ll store character vectors for the respective service groupings and then use them to filter the GTFS globally. We could also use the service IDs to filter individual data tables, like gtfs_fil$trips.\n\nm_f <- c(\"monday\", \"tuesday\", \"wednesday\", \"thursday\", \"friday\")\nsa_su <- c(\"saturday\", \"sunday\")\n\ngtfs_fil_m_f <- filter_by_weekday(gtfs_fil, m_f, combine = \"and\")\ngtfs_fil_sa_su <- filter_by_weekday(gtfs_fil, sa_su, combine = \"or\")\n\nunique(gtfs_fil_m_f$trips$service_id)\n\n[1] \"1\"\n\nunique(gtfs_fil_sa_su$trips$service_id)\n\n[1] \"2\" \"3\""
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "What can we learn from GTFS?\nSpecifically what can GTFS tell us about changes to Baltimore’s bus network?"
  },
  {
    "objectID": "about.html#baltimorelink",
    "href": "about.html#baltimorelink",
    "title": "About",
    "section": "BaltimoreLINK",
    "text": "BaltimoreLINK\nIn 2017, MDOT MTA rolled-out its redesigned bus network for Baltimore, called LINK.\n\nBaltimoreLink is a complete overhaul and rebranding of the core transit system operating within the city and throughout the greater Baltimore region. The bus network prior to BaltimoreLink had many routes that were antiquated, served outdated job locations and were too long to manage reliably, especially those that traversed downtown Baltimore and compounded congestion. -MDOT MTA, “BaltimoreLINK Basics”"
  },
  {
    "objectID": "about.html#whywhat-change",
    "href": "about.html#whywhat-change",
    "title": "About",
    "section": "Why/what “change”?",
    "text": "Why/what “change”?\nMDOT materials contemporary with LINK’s roll-out proclaim “In order to fix the system, we have to change the system.” What were the changes they made to the system? Has the system been fixed through these changes?\n\nLongest routes were shortened\nFrequencies increased on key routes\nCongestion-relief downtown\nImprove performance on 20 most frequently used routes"
  },
  {
    "objectID": "about.html#why-gtfs",
    "href": "about.html#why-gtfs",
    "title": "About",
    "section": "Why GTFS?",
    "text": "Why GTFS?\n\nThe General Transit Feed Specification (GTFS) is a data specification that allows public transit agencies to publish their transit data in a format that can be consumed by a wide variety of software applications. GTFS is split into a schedule component that contains schedule, fare, and geographic transit information and a real-time component that contains arrival predictions, vehicle positions and service advisories. - GTFS: Making Public Transit Data Universally Accessible\n\n\nGTFS is probably best known as the “feed” that is consumed by apps like Google Maps, Transit and Citymapper. It provides those applications with information about transit stops, the routes that serve them, when they are served and how much it costs to ride them. It is an open source data specification that supports a whole bunch of transit-related interfaces, basically."
  },
  {
    "objectID": "about.html#working-with-gtfs-in-r",
    "href": "about.html#working-with-gtfs-in-r",
    "title": "About",
    "section": "Working with GTFS in R",
    "text": "Working with GTFS in R\nTo learn more about working with GTFS in R, check out the “Calculating Headways” and “Bus Stop Wait Times” pages."
  },
  {
    "objectID": "cleaning_a_gtfs.html",
    "href": "cleaning_a_gtfs.html",
    "title": "Cleaning a GTFS using gtfstools",
    "section": "",
    "text": "Introducing GTFS and gtfstools\nOn this page, use some functions from gtfstools as well as the tidyverse to clean a GTFS. We will explore some of the structure of the GTFS and prepare it for calculations we will perform on subsequent pages.\n\nlibrary(gtfstools)\nlibrary(dplyr)\n\nread_gtfs reads a GTFS, holding it in your environment as a special datatable: a dt_gtfs.\n\ngtfs <- read_gtfs(\"./data/gtfs 11_2018.zip\")\nclass(gtfs)\n\n[1] \"dt_gtfs\" \"gtfs\"    \"list\"   \n\nsummary(gtfs)\n\nA gtfs object with the following tables and respective numbers of entries in each:\n        agency       calendar calendar_dates         routes         shapes \n             1              4              6            107         280190 \n    stop_times          stops      transfers          trips \n        745329           4726           1266          15484 \n\n\n\nThe data\nFor this exercise, we are using a GTFS published by the Maryland Transit Administration (MTA), containing information about service from September 2018 into February 2019. That information is contained, appropriately, in the “calendar” table of the dt_gtfs.\n\ngtfs$calendar$start_date\n\n[1] \"2018-09-02\" \"2018-09-02\" \"2018-09-02\" \"2018-09-02\"\n\ngtfs$calendar$end_date\n\n[1] \"2019-02-02\" \"2019-02-02\" \"2019-02-02\" \"2019-02-02\"\n\n\nThere are a bunch of other tables here, containing rows upon rows of information about transit service circa Fall and Winter, 2018-19. One of the tables is “routes” which contains information about route names and types.\n\nunique(gtfs$routes$route_type)\n\n[1] 3 1 0 2\n\n\n\n\n\nFiltering by route type\nIn the GTFS Reference, light rail is assigned type “0”, subway is assigned type “1”, intercity rail is assigned type “2”, and bus is assigned type “3”. Knowing this, we can use the filter_by_route_type function in gtfstools to filter the entire dt_gtfs to just the information about bus service.\n\n##filter down gtfs to just bus routes\ngtfs <- filter_by_route_type(gtfs, route_type = 3)\n##from 4 types to 1\nunique(gtfs$routes$route_type) \n\n[1] 3\n\n\nAgencies assign their own route_ids and these change with each new GTFS published. However, route_id corresponds to route_short_name, which does not change unless a route is eliminated or renamed.\n\nlength(unique(gtfs$routes$route_id))\n\n[1] 102\n\nlength(unique(gtfs$routes$route_short_name))\n\n[1] 102\n\n#it's 1:1\n\n\n\nFiltering buses\nIn the MTA bus system, routes 95 and greater are commuter and supplementary services. A number of these commuter routes serve Washington D.C. For this analysis, we are only interested in regular services in Baltimore City and that extend into surrounding Baltimore and Anne Arundel Counties.\nIn the next chunk, we will pass a range of numbers representing the extraneous bus routes to a character vector. Then, we will subset rows that have a route_short_name match in the character vector. We can pass the values from the resulting route_id column to a new character vector, which we can subsequently use with gtfstools filter_by_route_id function.\n\n##create vector of route short names\ncomm_names <- as.character(95:850)\n##subset route ids that have a match in the comm_names vector\nroute_ids <- gtfs$routes[which(gtfs$routes$route_short_name %in% comm_names), \"route_id\"]\n##pass the route ids to a new vector\ncomm_ids <- c(route_ids$route_id)\n##filter by route id\ngtfs_fil <- filter_by_route_id(gtfs, comm_ids, keep = FALSE) ##seeya\n\nlength(unique(gtfs_fil$routes$route_id))\n\n[1] 55\n\n\n\n\nTimes and days of the week\nGTFS stores arrival and departure times as a character in HH:MM:SS format.\n\nhead(gtfs_fil$stop_times$arrival_time)\n\n[1] \"20:43:00\" \"20:43:57\" \"20:44:53\" \"20:45:33\" \"20:46:15\" \"20:47:21\"\n\n\nThe convert_time_to_seconds function allows us to convert all arrival and departure times from HH:MM:SS format to seconds after midnight. This is going to make later calculations much easier. It also helps iron out some quirks that come with transit scheduling, since a single day of service can often extend beyond 24 hours.\n\ngtfs_fil <- convert_time_to_seconds(gtfs_fil)\nhead(gtfs_fil$stop_times$arrival_time_secs)\n\n[1] 74580 74637 74693 74733 74775 74841\n\n\nFinally, I’m going to break the GTFS down into weekday (Monday to Friday) and weekend (Saturday and Sunday) service. Service is often pared back on the weekends and it may be useful to exclude those trips from our subsequent calculations.\nAgencies assign service IDs to differentiate days of the week. There might be additional service IDs that pertain to special holiday or event services.\n\ngtfs_fil$calendar\n\n   service_id monday tuesday wednesday thursday friday saturday sunday\n1:          1      1       1         1        1      1        0      0\n2:          2      0       0         0        0      0        1      0\n3:          3      0       0         0        0      0        0      1\n   start_date   end_date\n1: 2018-09-02 2019-02-02\n2: 2018-09-02 2019-02-02\n3: 2018-09-02 2019-02-02\n\n\ngtfstools handles this type of filtering, once again, with a function. We’ll store character vectors for the respective service groupings and then use them to filter the GTFS globally. We could also use the service IDs to filter individual data tables, like gtfs_fil$trips.\n\nm_f <- c(\"monday\", \"tuesday\", \"wednesday\", \"thursday\", \"friday\")\nsa_su <- c(\"saturday\", \"sunday\")\n\ngtfs_fil_m_f <- filter_by_weekday(gtfs_fil, m_f, combine = \"and\")\ngtfs_fil_sa_su <- filter_by_weekday(gtfs_fil, sa_su, combine = \"or\")\n\nunique(gtfs_fil_m_f$trips$service_id)\n\n[1] \"1\"\n\nunique(gtfs_fil_sa_su$trips$service_id)\n\n[1] \"2\" \"3\""
  },
  {
    "objectID": "calculating_headways.html",
    "href": "calculating_headways.html",
    "title": "Calculating Headways",
    "section": "",
    "text": "library(gtfstools)\nlibrary(dplyr)\nlibrary(ggplot2)\n\n\nWhy calculate headways?\nAgencies publish loads of info about their services using GTFS, as we observed when cleaning our data. Some agencies publish optional information, such as frequencies.txt. This file provides information about how often a service runs. This file is used for services, such as the NYC Subway, that run at fixed intervals (e.g. every 4 minutes) rather than adhering to a schedule (e.g. departures at 13:00, 13:04, etc.) This table may also provide headways - time between departures from the same stop - for scheduled service.\nThe MTA does not publish frequencies.txt with their GTFS, but that doesn’t mean its not useful information to have. According to the Transit Capacity and Quality of Service Manual,\n\n“the longer the headway, the more inconvenient transit service becomes, both because passengers have to plan their trip around transit service and because they incur more unproductive time during their trip.” (Ch. 4, p. 28)\n\nHeadways greater than 10 minutes typically lead passengers to invest more time into their journeys to account for less-frequent service. Beyond 15 minutes, passengers must adapt to increasingly less-convenient departure and arrival times for their journeys. Headways upwards of 60 minutes provide “minimal” and “undesirable” service from a passenger’s point of view.\nHeadways as a proxy for quality of service can be used to compare service across agencies.\nAll this is just to reiterate - headways are a useful thing to have. A GTFS gives us all the information we need to calculate this measure, starting with trip_ids.\n\n\nFrom Trips to Patterns\nIn GTFS, trips are the most fine-grained keys in the data. A trip in GTFS corresponds to one bus travelling from its origin to its destination following a specific sequence of stops, in a single direction (inbound/outbound). A trip_id is generated for each scheduled trip for one week of service.\n\n#13k or so trips in this gtfs\n\nlength(unique(gtfs_fil$trips$trip_id))\n\n[1] 13246\n\n\nTrips are aggregated up to routes, which are sets of trips that serve roughly the same stops in the same sequence, inbound and outbound -- but origins, destinations, and stops served may vary. Routes may contain trips that have particular services depending on the time of day. Stops may be skipped during rush hour, or additional stops may be served to feed rail services.\nAn intermediate unit can be assigned by gtfstools: a pattern. Patterns group together trips that follow the same sequence of stops. There are far fewer patterns than there are trips, but more patterns than routes.\n\npatterns <- get_stop_times_patterns(gtfs_fil)\n\nlength(unique(patterns$pattern_id))\n\n[1] 287\n\n#resolution somewhere between trip_id and route_id\n\nEach pattern_id is associated with a different number of trips.\n\ncount(patterns, pattern_id)\n\n     pattern_id   n\n  1:          1 112\n  2:          2 112\n  3:          3 169\n  4:          4 170\n  5:          5 126\n ---               \n283:        283   1\n284:        284   1\n285:        285   1\n286:        286   1\n287:        287   1\n\n\nLooking at the start and end of this table, we have patterns that are associated with a single trip, or patterns that are associated with over 100 trips. We will use pattern_id as a grouping variable when we calculate headways.\nMost of our cleaning operations were performed globally, but here the first step is to break out the GTFS stop_times table to which we will join the patterns table we created earlier. stop_times is the most fine-grained table in the GTFS; it reports where and in what sequence each trip_id stops along its journey. When we will add to this table pattern IDs as well as route_short_names for grouping and stats we can use later.\n\n##in the first line we are linking patterns to stop_times via trip_id\nstop_times_patt <- left_join(gtfs_fil_m_f$stop_times, patterns, by=\"trip_id\")%>%\n  ##then we pipe the joined table to another join, route_id via trip_id\n  left_join(gtfs_fil_m_f$trips[ , c(\"trip_id\", \"route_id\")], by = \"trip_id\", keep = FALSE)%>%\n  ##then we pipe it one more time to join route_short_name via route_id\n  left_join(gtfs_fil_m_f$routes[ , c(\"route_id\", \"route_short_name\")], by = \"route_id\", keep = FALSE)\nnames(stop_times_patt)\n\n [1] \"trip_id\"             \"arrival_time\"        \"departure_time\"     \n [4] \"stop_id\"             \"stop_sequence\"       \"stop_headsign\"      \n [7] \"pickup_type\"         \"drop_off_type\"       \"shape_dist_traveled\"\n[10] \"departure_time_secs\" \"arrival_time_secs\"   \"pattern_id\"         \n[13] \"route_id\"            \"route_short_name\"   \n\n\n\n\nSetting the Grouping Variables\nA headway is the time between when buses arrive at the same stop. If trip_1 of Route A arrives at Stop X at 15:00 and trip_2 of Route A arrives at Stop X at 15:10, Route A has a headway of 10 minutes. We know that trip_id is unique for every scheduled trip, and that route_id is agnostic when it comes to origins, destinations, and everything in between. pattern_id, as noted when we cleaned the GTFS, is a handy-middle ground.\nWe will use pattern_id along with stop_id as grouping variables so we can calculate headways as illustrated in my simple formulation above. After we group, we arrange by departure time; this is necessary because trip_ids are not arranged chronologically in the GTFS. As published, many trips appear to “leapfrog” each other, which can cause sequentially scheduled trips to appear further apart than they really are.\n\nstop_times_patt_grp <- group_by(stop_times_patt, pattern_id, stop_id) %>% arrange(departure_time_secs, .by_group = TRUE)\n\n\n\nRunning the Headway Calculation\nWe are ready to calculate headways. We subtract arrival_time_secs at each stop from arrival_time_secs of the preceding trip using lag, which respects our grouping variables.\n\n##calculate difference in seconds between arrivals at each stop, by trip\nheadways <- mutate(stop_times_patt_grp, diff = arrival_time_secs-lag(arrival_time_secs)) %>%\n  ##convert seconds to minutes\n  mutate(headway_m = diff/60)\nrange(headways$headway_m, na.rm = TRUE)\n\n[1]    0 1260\n\n\nTo illustrate, we can filter out a single pattern and observe how we lagged the difference within pattern_id 2 of arrival_time_secs at the second sequential stop of the pattern. The first row is NA because it is the first trip of pattern_id 2; there are no preceding trips from which to calculate difference.\n\npat_2 <- filter(headways, pattern_id == \"2\", stop_sequence == 2)\nhead(pat_2$arrival_time_secs)\n\n[1] 14443 17323 20503 23450 26030 28010\n\nhead(pat_2$diff)\n\n[1]   NA 2880 3180 2947 2580 1980\n\n\nThe TCQSM as well as Wong (2013) recommend removing headways of less than 3 minutes and greater than 90 minutes to exclude school services and breaks in service.\n\n##subsetting using base, as dplyr::filter would get rid of NAs\nheadways_fil <- headways[headways$headway_m > 3 & headways$headway_m < 90,]\nrange(headways_fil$headway_m, na.rm = TRUE)\n\n[1]  3.033333 89.650000\n\n\n\n\nPlotting the distribution of bus headways\nWe will use our new headway variables in subsequent calculations, like stop wait times. For now, let’s plot a histogram of headways grouped by route_id.\n\nheadways_mean <- headways_fil %>% group_by(route_short_name)%>%\n  summarise(mean_hw = mean(headway_m))\n##spit out plot\nggplot(headways_mean, aes(x=mean_hw)) +\n  ##MTA colors\n  geom_histogram(binwidth = 5, color = \"#FDB90B\", fill = \"#A30330\", na.rm = TRUE) +\n  scale_x_continuous(name = \"Mean Headways by Routes (minutes)\", breaks=seq(5,90,5))+\n  ylab(\"Count (Routes)\") +\n  theme(panel.grid.minor.y = element_blank(),\n        panel.grid.major.x = element_blank(),\n        panel.grid.minor.x = element_blank())\n\n\n\n\n\n\nPlotting Headways and Trip Count by Route\nWhile it’s neat to have a distribution of headways, showing that most routes are hanging around 40 minutes, why don’t we get a sense of what mean headway is for each route? While we’re doing that, why don’t we get some other stats? One thing that might be particularly interesting is how many trips run on each route per day. We have can see there’s some outliers on this histogram - do those routes make very many trips? Let’s see.\n\nheadways_rt <- group_by(headways_fil, route_short_name) %>% #group based on route name\n  summarise(mean = mean(headway_m), #calculate mean headway of each route\n            median = median(headway_m), #get the medians to catch anything skew\n            count = length(unique(trip_id)) #get a count of how many trips run on each route\n            )%>% arrange(mean)\n\nggplot(na.omit(headways_rt), aes(x = reorder(route_short_name, -mean), y = mean, label = count))+\n  geom_col(aes(fill = median)) +\n  coord_flip() +\n  geom_text(check_overlap = TRUE, color = \"white\", position = position_dodge(0.9), hjust = 0) +\n    scale_fill_distiller(palette = \"PuBuGn\", direction = 1, name = \"Median\") +\n    xlab(\"Bus Routes\") +\n  scale_y_continuous(name = \"Mean Headway (min.)\", breaks=seq(5,60,5))   +\n  theme_dark() +\n  ggtitle(\"MTA Bus Routes - Headways and Trip Counts\")\n\n\n\n\nNow this is much more informative. We can see that those two bins on either side of the histogram are made up of a single route. One of those routes, Route 38 which has 5 minute headways, actually only runs once a day. Route 52 and Route 92 only run once a day and five times a day, respectively. Next time we run this analysis, we might add those routes to the ones we purge when we clean the GTFS."
  },
  {
    "objectID": "state_rider_mix.html",
    "href": "state_rider_mix.html",
    "title": "Replicating Erin Davis’ ‘viral map’ with public transit ridership data",
    "section": "",
    "text": "In this vignette, I will adapt Erin Davis’ viral map using public transit ridership data. Using U.S. Census ACS data, we can make a similar map to show how the “ridership mix” in each state has changed from 2011-2021. The ACS collects data in the Transportation to Work universe, capturing which public transit modes use at the tract or block-group level. The ACS has estimates for commuter/long-distance rail, ferry, subway/elevated rail, trolley/streetcar and bus. The first thing we need to do is find and store the unique name variable the Census uses for each mode.\n\n##the variables for each mode were unchanged from 2011-2018\npt <- c(\"B08301_010\") #total using public transportation\nbus <- c(\"B08301_011\")\nsubway <- c(\"B08301_013\")\ncomm_rail <- c(\"B08301_014\")\ntrolley <- c(\"B08301_012\")\nferry <- c(\"B08301_015\")\n##when we call 2019-2021 ACS data, we will change the following vars\n##subway.19 <- c(\"B08301_012\")\n##comm_rail.19 <- c(\"B08301_013\")\n##trolley.19 <- c(\"B08301_014\")\n\nWhen we call tidycensus for the ACS data, we will rename each variable. We will also include functions to clean the data as well as calculate percentages for each share of each mode. It’s going to look pretty clunky. I will share the first call in the chunk below with commentary.\n\npt.2021 <- get_acs(geography = \"state\", \n                   variables = c(\"pt\" = pt,\n                                 \"bus\" = bus,\n                                 \"subway\" = \"B08301_012\", #19-21 ACS used a different variable for these three modes, so I'm not using the stored vars\n                                 \"comm_rail\" = \"B08301_013\",\n                                 \"trolley\" = \"B08301_014\",\n                                 \"ferry\" = ferry),\n                   year = 2021,\n                   survey = \"acs5\",\n                   output = \"wide\")\n\nWe need wide data to easily calculate the new percentage columns (I know no other way!). However, that leads to some clunky cumbersome colnames, some of which we will rename, others will be dropped entirely.\n\ncolnames(pt.2021)\n\n [1] \"GEOID\"      \"NAME\"       \"ptE\"        \"ptM\"        \"busE\"      \n [6] \"busM\"       \"subwayE\"    \"subwayM\"    \"comm_railE\" \"comm_railM\"\n[11] \"trolleyE\"   \"trolleyM\"   \"ferryE\"     \"ferryM\"    \n\n\nIn the next chunk, we store the colnames that we want to drop, calculate new columns, drop the unneeded columns, and finally pivot_longer which will be important for how we construct our plots later.\n\ndrop <- c(\"ptM\",\n          \"busM\",\n          \"comm_railM\",\n          \"subwayM\",\n          \"trolleyM\",\n          \"totpopM\",\n          \"busE\",\n          \"ferryM\",\n          \"ptE\",\n          \"comm_railE\",\n          \"subwayE\",\n          \"trolleyE\",\n          \"ferryE\") ##colnames that are soon to leave us\n ##add a year column\npt.2021$year <- 2021 \npt.2021 <- pt.2021%>% \n  mutate(##calculating new columns - part (mode) / whole (ptE or estimate of total ridership) * 100\n    Ferry_Perc = ferryE / ptE * 100,\n    Trolley_Perc = trolleyE / ptE * 100,\n    Subway_Perc =  subwayE / ptE * 100,\n    Comm_Rail_Perc = comm_railE / ptE * 100, \n    Bus_Perc = busE / ptE * 100)%>%\n  select(!(contains(c(drop))))%>% ##using tidy_select to drop the unwanted columns\n  pivot_longer(##pivoting longer for ggplot's sake\n    cols = ends_with(\"_Perc\"),\n    names_to = \"variables\",\n    values_to = \"estimate\")\nhead(pt.2021)\n\n# A tibble: 6 × 5\n  GEOID NAME     year variables      estimate\n  <chr> <chr>   <dbl> <chr>             <dbl>\n1 01    Alabama  2021 Ferry_Perc        2.37 \n2 01    Alabama  2021 Trolley_Perc      1.76 \n3 01    Alabama  2021 Subway_Perc       0.310\n4 01    Alabama  2021 Comm_Rail_Perc    1.04 \n5 01    Alabama  2021 Bus_Perc         94.5  \n6 02    Alaska   2021 Ferry_Perc       11.1  \n\n\nLooks like we were successful. Let’s do this again for 9 more years of data. Wouldn’t it be cool to do this in a function? Maybe one day!\n\npt.2020 <- get_acs(geography = \"state\", \n                   variables = c(\"pt\" = pt,\n                                 \"bus\" = bus,\n                                 \"subway\" = \"B08301_012\",\n                                 \"comm_rail\" = \"B08301_013\",\n                                 \"trolley\" = \"B08301_014\",\n                                 \"ferry\" = ferry\n                                 ),\n                   year = 2020,\n                   survey = \"acs5\",\n                   output = \"wide\")\npt.2020$year <- 2020\n\npt.2020 <- pt.2020 %>% \n  mutate(\n    Ferry_Perc = ferryE / ptE * 100,\n    Trolley_Perc = trolleyE / ptE * 100,\n    Subway_Perc =  subwayE / ptE * 100,\n    Comm_Rail_Perc = comm_railE / ptE * 100, \n    Bus_Perc = busE / ptE * 100\n    )%>%\n  select(!(contains(c(drop))))%>%\n  pivot_longer(\n    cols = ends_with(\"_Perc\"),\n    names_to = \"variables\",\n    values_to = \"estimate\")\n\n\n\n\npt.2019 <- get_acs(geography = \"state\", \n                   variables = c(\"pt\" = pt,\n                                 \"bus\" = bus,\n                                 \"subway\" = \"B08301_012\",\n                                 \"comm_rail\" = \"B08301_013\",\n                                 \"trolley\" = \"B08301_014\",\n                                 \"ferry\" = ferry\n                                 ),\n                   year = 2019,\n                   survey = \"acs5\",\n                   output = \"wide\")\npt.2019$year <- 2019\n\npt.2019 <- pt.2019 %>% \n  mutate(\n    Ferry_Perc = ferryE / ptE * 100,\n    Trolley_Perc = trolleyE / ptE * 100,\n    Subway_Perc =  subwayE / ptE * 100,\n    Comm_Rail_Perc = comm_railE / ptE * 100, \n    Bus_Perc = busE / ptE * 100\n    )%>%\n  select(!(contains(c(drop))))%>%\n  pivot_longer(\n    cols = ends_with(\"_Perc\"),\n    names_to = \"variables\",\n    values_to = \"estimate\")\n\npt.2018 <- get_acs(geography = \"state\", \n                   variables = c(\"pt\" = pt,\n                                 \"bus\" = bus,\n                                 \"subway\" = subway, ##from 2018, we can use our stored variables\n                                 \"comm_rail\" = comm_rail,\n                                 \"trolley\" = trolley,\n                                 \"ferry\" = ferry\n                                 ),\n                   year = 2018,\n                   survey = \"acs5\",\n                   output = \"wide\")\npt.2018$year <- 2018\n\npt.2018 <- pt.2018 %>% \n  mutate(\n    Ferry_Perc = ferryE / ptE * 100,\n    Trolley_Perc = trolleyE / ptE * 100,\n    Subway_Perc =  subwayE / ptE * 100,\n    Comm_Rail_Perc = comm_railE / ptE * 100, \n    Bus_Perc = busE / ptE * 100\n    )%>%\n  select(!(contains(c(drop))))%>%\n  pivot_longer(\n    cols = ends_with(\"_Perc\"),\n    names_to = \"variables\",\n    values_to = \"estimate\")\n\n\npt.2017 <- get_acs(geography = \"state\", \n                   variables = c(\"pt\" = pt,\n                                 \"bus\" = bus,\n                                 \"subway\" = subway,\n                                 \"comm_rail\" = comm_rail,\n                                 \"trolley\" = trolley,\n                                 \"ferry\" = ferry\n                                 ),\n                   year = 2017,\n                   survey = \"acs5\",\n                   output = \"wide\")\npt.2017$year <- 2017\n\npt.2017 <- pt.2017 %>% \n  mutate(\n    Ferry_Perc = ferryE / ptE * 100,\n    Trolley_Perc = trolleyE / ptE * 100,\n    Subway_Perc =  subwayE / ptE * 100,\n    Comm_Rail_Perc = comm_railE / ptE * 100, \n    Bus_Perc = busE / ptE * 100\n    )%>%\n  select(!(contains(c(drop))))%>%\n  pivot_longer(\n    cols = ends_with(\"_Perc\"),\n    names_to = \"variables\",\n    values_to = \"estimate\")\n\n\npt.2016 <- get_acs(geography = \"state\", \n                   variables = c(\"pt\" = pt,\n                                 \"bus\" = bus,\n                                 \"subway\" = subway,\n                                 \"comm_rail\" = comm_rail,\n                                 \"trolley\" = trolley,\n                                 \"ferry\" = ferry\n                                 ),\n                   year = 2016,\n                   survey = \"acs5\",\n                   output = \"wide\")\npt.2016$year <- 2016\n\npt.2016 <- pt.2016 %>% \n  mutate(\n    Ferry_Perc = ferryE / ptE * 100,\n    Trolley_Perc = trolleyE / ptE * 100,\n    Subway_Perc =  subwayE / ptE * 100,\n    Comm_Rail_Perc = comm_railE / ptE * 100, \n    Bus_Perc = busE / ptE * 100\n    )%>%\n  select(!(contains(c(drop))))%>%\n  pivot_longer(\n    cols = ends_with(\"_Perc\"),\n    names_to = \"variables\",\n    values_to = \"estimate\")\n\n\npt.2015 <- get_acs(geography = \"state\", \n                   variables = c(\"pt\" = pt,\n                                 \"bus\" = bus,\n                                 \"subway\" = subway,\n                                 \"comm_rail\" = comm_rail,\n                                 \"trolley\" = trolley,\n                                 \"ferry\" = ferry\n                                 ),\n                   year = 2015,\n                   survey = \"acs5\",\n                   output = \"wide\")\npt.2015$year <- 2015\n\npt.2015 <- pt.2015 %>% \n  mutate(\n    Ferry_Perc = ferryE / ptE * 100,\n    Trolley_Perc = trolleyE / ptE * 100,\n    Subway_Perc =  subwayE / ptE * 100,\n    Comm_Rail_Perc = comm_railE / ptE * 100, \n    Bus_Perc = busE / ptE * 100\n    )%>%\n  select(!(contains(c(drop))))%>%\n  pivot_longer(\n    cols = ends_with(\"_Perc\"),\n    names_to = \"variables\",\n    values_to = \"estimate\")\n\npt.2014 <- get_acs(geography = \"state\", \n                   variables = c(\"pt\" = pt,\n                                 \"bus\" = bus,\n                                 \"subway\" = subway,\n                                 \"comm_rail\" = comm_rail,\n                                 \"trolley\" = trolley,\n                                 \"ferry\" = ferry\n                                 ),\n                   year = 2014,\n                   survey = \"acs5\",\n                   output = \"wide\")\npt.2014$year <- 2014\n\npt.2014 <- pt.2014 %>% \n  mutate(\n    Ferry_Perc = ferryE / ptE * 100,\n    Trolley_Perc = trolleyE / ptE * 100,\n    Subway_Perc =  subwayE / ptE * 100,\n    Comm_Rail_Perc = comm_railE / ptE * 100, \n    Bus_Perc = busE / ptE * 100\n    )%>%\n  select(!(contains(c(drop))))%>%\n  pivot_longer(\n    cols = ends_with(\"_Perc\"),\n    names_to = \"variables\",\n    values_to = \"estimate\")\n\npt.2013 <- get_acs(geography = \"state\", \n                   variables = c(\"pt\" = pt,\n                                 \"bus\" = bus,\n                                 \"subway\" = subway,\n                                 \"comm_rail\" = comm_rail,\n                                 \"trolley\" = trolley,\n                                 \"ferry\" = ferry\n                                 ),\n                   year = 2013,\n                   survey = \"acs5\",\n                   output = \"wide\")\npt.2013$year <- 2013\n\npt.2013 <- pt.2013 %>% \n  mutate(\n    Ferry_Perc = ferryE / ptE * 100,\n    Trolley_Perc = trolleyE / ptE * 100,\n    Subway_Perc =  subwayE / ptE * 100,\n    Comm_Rail_Perc = comm_railE / ptE * 100, \n    Bus_Perc = busE / ptE * 100\n    )%>%\n  select(!(contains(c(drop))))%>%\n  pivot_longer(\n    cols = ends_with(\"_Perc\"),\n    names_to = \"variables\",\n    values_to = \"estimate\")\n\n\npt.2012 <- get_acs(geography = \"state\", \n                   variables = c(\"pt\" = pt,\n                                 \"bus\" = bus,\n                                 \"subway\" = subway,\n                                 \"comm_rail\" = comm_rail,\n                                 \"trolley\" = trolley,\n                                 \"ferry\" = ferry\n                                 ),\n                   year = 2012,\n                   survey = \"acs5\",\n                   output = \"wide\")\npt.2012$year <- 2012\n\npt.2012 <- pt.2012 %>% \n  mutate(\n    Ferry_Perc = ferryE / ptE * 100,\n    Trolley_Perc = trolleyE / ptE * 100,\n    Subway_Perc =  subwayE / ptE * 100,\n    Comm_Rail_Perc = comm_railE / ptE * 100, \n    Bus_Perc = busE / ptE * 100\n    )%>%\n  select(!(contains(c(drop))))%>%\n  pivot_longer(\n    cols = ends_with(\"_Perc\"),\n    names_to = \"variables\",\n    values_to = \"estimate\")\n\n\npt.2011 <- get_acs(geography = \"state\", \n                   variables = c(\"pt\" = pt,\n                                 \"bus\" = bus,\n                                 \"subway\" = subway,\n                                 \"comm_rail\" = comm_rail,\n                                 \"trolley\" = trolley,\n                                 \"ferry\" = ferry\n                                 ),\n                   year = 2011,\n                   survey = \"acs5\",\n                   output = \"wide\")\npt.2011$year <- 2011\n\npt.2011 <- pt.2011 %>% \n  mutate(\n    Ferry_Perc = ferryE / ptE * 100,\n    Trolley_Perc = trolleyE / ptE * 100,\n    Subway_Perc =  subwayE / ptE * 100,\n    Comm_Rail_Perc = comm_railE / ptE * 100, \n    Bus_Perc = busE / ptE * 100\n    )%>%\n  select(!(contains(c(drop))))%>%\n  pivot_longer(\n    cols = ends_with(\"_Perc\"),\n    names_to = \"variables\",\n    values_to = \"estimate\")\n\nWe have a few more cleaning steps left to do, “globally” or on all our new variables. First, we will use rbind to make a long table with a single variable column.\n\npt.decade <- rbind(pt.2011, pt.2012, pt.2013, pt.2014, pt.2015, pt.2016, pt.2017, pt.2018, pt.2019, pt.2020, pt.2021)\n\nIn the next chunk, we filter to remove Puerto Rico, drop decimals with round() and then add a column with two-letter state abbreviations to make our final plot look oh-so nice.\n\n#remove PR\npt.decade <- pt.decade %>%\n  filter(GEOID < 70)\n\n#drop everything from the hundreds place on\npt.decade$estimate <- round(pt.decade$estimate, digits = 1)\n\n#add abreviations\nabbs <- tibble(NAME = state.name)%>% ##state.name and .abb are handy base r functions!\n  bind_cols(tibble(abb = state.abb)) %>% \n  bind_rows(tibble(NAME = \"District of Columbia\", abb = \"DC\")) ##but they don't include DC?\npt.decade <- left_join(pt.decade, abbs, by = \"NAME\")\n\nIn the next chunk, we store some variables which will be useful when we start plotting.\n\n##limits for x and y axes\nfirstyear <- 2011\nlastyear <- 2021\n\n#titles are cool\nplottitle <- 'Public Transportation Ridership Mix by State'\n\n\n#making a new column called Mode that will also refactor the variables in the way we want them to appear in the plot\npt.decade$Mode <- factor(pt.decade$variables, levels=c(\"Ferry_Perc\", \n                                                    \"Comm_Rail_Perc\",\n                                                       \"Trolley_Perc\",\n                                                       \"Bus_Perc\",\n                                                       \"Subway_Perc\"))\n\n\n#storing the colors we want for each mode\ncolors <- c(\"Ferry_Perc\" = \"#9d9d9d\",\n            \"Comm_Rail_Perc\" = \"#2f5da6\",\n            \"Trolley_Perc\" = \"#fd8a03\",\n            \"Bus_Perc\" = \"#36bbed\",\n            \"Subway_Perc\" = \"#fa2d27\"\n)\n\n#going to use this variable to rename our legend items\nmodes<-c(\"Ferry\", \n      \"Commuter/LD Rail\",\n      \"Light Rail/Trolley\",\n      \"Bus\",\n      \"Subway\")\n\nIn the next chunk, we will make a test plot which will double as our legend. We will use Alaska, a clever move by Davis.\n\nlegend_AK <- ggplot(data = subset(pt.decade, NAME == 'Alaska'), aes(x = year, y = estimate, fill = Mode, group = Mode)) + \n  geom_area()+\n  annotate(\"text\", x = 2018, y = 20, \n           label = \"AK\", \n           size = 5, \n           colour = \"#222222\")+\n  scale_fill_manual(values = colors,\n                    labels = modes) +\n  scale_x_continuous(limits = c(firstyear, lastyear), expand = c(0,0))+\n  scale_y_continuous(limits = c(0, 101),\n                     expand = c(0, 0),\n                     breaks = c(25, 50, 75, 100)) +\n      theme(legend.position = 'left',\n      legend.key.height = unit(.25, 'cm'),\n      legend.key.width = unit(.5, 'cm'),\n      legend.text = element_text(size = 7),\n      legend.title = element_text(size = 7),\n      aspect.ratio=1, \n      panel.background = element_rect(fill = '#efefef', color = '#f6f6f6'), \n      axis.title = element_blank(),\n      axis.ticks = element_blank(),\n      axis.text.y = element_text(size = 2.5,\n                                 colour = \"#222222\"),\n      axis.text.x = element_blank(),\n      plot.margin = grid::unit(c(0,0,0,0), \"mm\"))\nlegend_AK\n\n\n\n\nPretty cool! I have no idea who is commuting to work in Alaska by subway or light rail. Congresspeople? Alaskan-New Yorkers?\nNext up, we have a function that comes pretty much line-by-line from Davis. It makes a list of all the unique values in the abb column then plugs each value into the function, spitting out a plot for all 50 states plus D.C.\n\nstates <- unique(pt.decade$abb) # get the unique state names\nstates <- states[!grepl('AK', states)] # not using filter, because this is a list\n\nfor (i in 1:length(states)) {\n  plot <- ggplot(subset(pt.decade, abb == states[i]), \n                 aes(x = year, y = estimate, \n                     fill = Mode, group = Mode)) + \n    theme_map() +\n    geom_area() +\n    annotate(\"text\", x = 2018, y = 20, \n             label = states[i], \n             size = 2, \n             colour = \"#222222\") +\n    scale_fill_manual(values = colors) +\n    scale_x_continuous(limits = c(firstyear, lastyear), expand = c(0, 0)) +\n    scale_y_continuous(limits = c(0, 100.9))+ \n    theme(legend.position = 'none', \n          aspect.ratio=1, \n          #panel.background =  element_rect(fill = '#efefef', color = '#f6f6f6'), \n          axis.text.y = element_blank(),\n          axis.text.x = element_blank(),\n          plot.margin=grid::unit(c(0,0,0,0), \"mm\"))\n  assign(states[i], plot)\n  remove(plot)\n}\nOK #print a test plot\n\n\n\n\nThe OKC Streetcar went live in 2018, and you can see that right here, where the orange line goes real wide.\nThere’s really nothing left to do but make a layout and create a patchwork object. Once again, this comes nearly line by line from Davis. She has a great explanation of how this layout works on the post linked above.\n\nlayout<-c(\n    area(1,1,2,4),\n  area(2,11),\n  area(3,10),area(3,11),\n  area(4,1),area(4,2),area(4,3),area(4,4),area(4,5),\n  area(4,7),area(4,9),area(4,10),area(4,11),\n  area(5,1),area(5,2),area(5,3),area(5,4),area(5,5),\n  area(5,6),area(5,7),area(5,8),area(5,9),area(5,10),\n  area(6,1),area(6,2),area(6,3),area(6,4),area(6,5),\n  area(6,6),area(6,7),area(6,8),area(6,9),area(6,10),\n  area(7,2),area(7,3),area(7,4),area(7,5),area(7,6),\n  area(7,7),area(7,8),area(7,9),area(7,10),\n  area(8,3),area(8,4),area(8,5),area(8,6),area(8,7),area(8,8),\n  area(9,1),area(9,4),area(9,10)\n)\n\nfinalplot <- wrap_plots(legend_AK, \n                        ME, VT, NH, WA, ID, MT, ND, MN, MI, NY, MA, RI,\n                        OR, UT, WY, SD, IA, WI, OH, PA, NJ, CT,\n                        CA, NV, CO, NE, IL, IN, WV, VA, MD, DE,\n                        AZ, NM, KS, MO, KY, TN, SC, NC, DC,\n                        OK, LA, AR, MS, AL, GA, HI, TX, FL,\n                        design = layout) &\n #rather than use ggplot for the title, I'm using patchwork's annotation functions\n  plot_annotation(title = plottitle, \n                  caption = \"Data: U.S. Census 2011-2021 ACS 5 Year\n                                Compiled with tidycensus (Walker 2023) \n                                Adapted from Erin Davis, 'How I Made The Viral Map'\",\n                  theme = theme(plot.background = element_rect(color  = '#f8f8f8')))\nfinalplot"
  },
  {
    "objectID": "calculating_stop_waits.html",
    "href": "calculating_stop_waits.html",
    "title": "Calculating Stop Waits",
    "section": "",
    "text": "Where is the longest wait for a bus?\nWe calculated headways, which gives us a sense of service frequencies at the route level. What does this look like at the stop level? What stops receive the most service and what stops receive the least? What stops experience the longest waits between buses? By calculating some simple summary statistics, we can figure that out. Then, we’ll use those to make some maps.\n\nlibrary(gtfstools)\nlibrary(tidyverse)\nlibrary(sf)\n\n\n\nAdding new grouping variables\nWe’ll start by removing grouping from the headways table we created on the last page.\n\nheadways_fil <- ungroup(headways_fil)\n\nNext, we group by stop_id, since that is now the scale of the data we are interested in (as opposed to routes and patterns in the case of headways). To get the mean wait time at each stop, we just summarise each stop_id by the mean of the headway column. Incredibly, we can do this pretty sizable calculation, that summarizes thousands of rows of data into a few hundred, in a very small code block, thanks to the power of magrittr’s %>%.\n\nstop_waits <- headways_fil %>% ##calling the headways table\n              group_by(stop_id) %>% ##grouping by stop_id\n              summarise(mean_wait = mean(headway_m, na.rm = TRUE))\n\n\n\nMaking it spatial\nThe stops table of a GTFS has longitude and latitude information that we can join to our new table of mean waits.\n\n#storing the names of the lat-long colummns as a character vector\ncoordinates = c(\"stop_lon\", \"stop_lat\")\n\n#joining our table of mean waits to the stops table from the gtfs\nstop_join <- inner_join(stop_waits, gtfs_fil$stops) \n\nJoining with `by = join_by(stop_id)`\n\n#make it spatial\nstop_join <- st_as_sf(stop_join, coords = coordinates, crs = 4326)\n\n\n\nMapping bus stop wait times\nNow let’s make a quick map using ggplot.\n\nggplot(stop_join) +\n  geom_sf(aes(color = mean_wait), size = 1.5) +\n  scale_colour_distiller(palette = \"YlGnBu\", direction = 1)\n\n\n\n\nThis confirms what we might have already guessed: the shortest wait times appear to be in the core of the service area, Baltimore’s downtown. But where are the longest waits?\n\nlibrary(mapview)\n#grab 25 longest waits\ntop_25 <- stop_join %>%\n  slice_max(mean_wait, n = 25) \n\nmapview(top_25)\n\n\n\n\n\n\nIt looks like the top 25 stops based on wait time are in the inner suburbs to Baltimore’s northwest, an area of Northwest Anne Arundel County, and one lonely stop in Dundalk. It might be worth further investigating service at these stops. For example, how many bus trips do they receive per day? If it’s less than a dozen, that could account for the long waits and perhaps we may exclude them from future analyses."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Analyzing Transit Data",
    "section": "",
    "text": "Welcome! My name is Joe Gallagher. This page originated during my studies in the Department of Geography and Environmental Systems at UMBC, where I am a PhD student. I am using this site to share some work I’ve been doing with transit data in R. Most of the content in here is about working with GTFS data, although there is one vignette so far about working with transit data from the U.S. Census. Read on to see how GTFS can be used to understand transit in Baltimore and the U.S."
  }
]